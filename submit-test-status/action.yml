---
name: Submit Test Status

description: Submits test status records from a GHA workflow job to CI Analytics. See https://confluence.camunda.com/display/HAN/CI+Analytics

inputs:
  test_event_record:
    description: Test event(s) in JSONL format. Required keys are test_name and test_status.
    required: true

  gcp_credentials_json:
    description: Credentials for a Google Cloud ServiceAccount allowed to publish to Big Query formatted as contents of credentials.json file.
    required: true

  big_query_table_name:
    description: Use only for infrastructure testing purposes to target e.g. dev environment.
    required: false
    default: 'ci-30-162810:prod_ci_analytics.test_status_v1'


runs:
  using: composite
  steps:
  - name: Echo inputs
    shell: bash
    run: |
      echo "Inputs"
      echo "-----"
      echo "Test event record: ${{ inputs.test_event_record }}"
      echo "BQ table name (for testing): ${{ inputs.big_query_table_name }}"

  - name: login to Google Cloud
    id: auth
    uses: google-github-actions/auth@v2
    with:
      credentials_json: '${{ inputs.gcp_credentials_json }}'

  - name: setup Google Cloud SDK
    uses: google-github-actions/setup-gcloud@v2

  - name: Print Google Cloud SDK version used
    shell: bash
    run: |
      gcloud info

  - name: ensure that jq is available
    uses: dcarbone/install-jq-action@v3.0.1

  - name: download and convert table schema
    shell: bash
    env:
      BQ_COMMAND: "${{ (runner.os == 'Windows') && 'bq.cmd' || 'bq' }}"
    run: |
      schema_file="${{ runner.temp }}/sts/table_schema.json"
      converted_schema_file="${{ runner.temp }}/sts/converted_schema.json"

      # download schema from CI Analytics
      mkdir ${{ runner.temp }}/sts
      $BQ_COMMAND show \
        --format prettyjson \
        "${{ inputs.big_query_table_name }}" \
      | jq '.schema.fields' > $schema_file

      # convert schema for the further validation to JSON schema specs format
      jq '{
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": (reduce .[] as $field ({}; . + {
          ($field.name): {
            "type": ($field.type | ascii_downcase | if . == "timestamp" then "string" else . end | if $field.mode == "NULLABLE" then [., "null"] else . end),
            "format": (if $field.type == "TIMESTAMP" then "date-time" else null end)
          }
        })),
        "required": [.[] | select(.mode == "REQUIRED") | .name]
      }' "$schema_file" > "$converted_schema_file"

      echo "Converted schema saved to $converted_schema_file"

  - name: load input and add required keys
    shell: bash
    env:
      TEMP_DIR: ${{ runner.temp }}/sts
    run: |
      cat <<EOF > $TEMP_DIR/input_test_event_record.json
      ${{ inputs.test_event_record }}
      EOF
      # add mandatory report_time, ci_url and build_id to the test records
      REPORT_TIME=$(date '+%Y-%m-%d %H:%M:%S')
      jq -c \
        --arg REPORT_TIME "$REPORT_TIME" \
        --arg CI_URL "$GITHUB_SERVER_URL/$GITHUB_REPOSITORY" \
        --arg BUILD_ID "$GITHUB_RUN_ID/$GITHUB_RUN_ATTEMPT" \
        '. + {"report_time": $REPORT_TIME} + {"ci_url": $CI_URL} + {"build_id": $BUILD_ID}' \
        $TEMP_DIR/input_test_event_record.json > $TEMP_DIR/test_event_record.json
      # convert test record from JSONL to JSON format for validation
      jq -s '.' $TEMP_DIR/test_event_record.json > $TEMP_DIR/converted_test_event_record.json


  - name: validate input
    env:
      TEMP_DIR: ${{ runner.temp }}/sts
    uses: dsanders11/json-schema-validate-action@v1.2.0
    with:
      schema: ${{ env.TEMP_DIR }}/converted_schema.json
      files: ${{ env.TEMP_DIR }}/converted_test_event_record.json

      # # validate input for the presence of mandatory keys
      # INVALID_LINES=$(jq -c 'select((has("test_name") and has("test_status")) | not)' "$TEMP_DIR/input_test_event_record.json")
      # if [ -n "$INVALID_LINES" ]; then
      #   echo "JSONL input validation failed. The following lines are invalid:"
      #   echo "$INVALID_LINES"
      #   exit 1
      # fi

  - name: submit to CI Analytics
    shell: bash
    env:
      TEMP_DIR: ${{ runner.temp }}/sts
      BQ_COMMAND: "${{ (runner.os == 'Windows') && 'bq.cmd' || 'bq' }}"
    run: |
      # # add mandatory report_time, ci_url and build_id to the test records
      # REPORT_TIME=$(date '+%Y-%m-%d %H:%M:%S')
      # jq -c \
      #   --arg REPORT_TIME "$REPORT_TIME" \
      #   --arg CI_URL "$GITHUB_SERVER_URL/$GITHUB_REPOSITORY" \
      #   --arg BUILD_ID "$GITHUB_RUN_ID/$GITHUB_RUN_ATTEMPT" \
      #   '. + {"report_time": $REPORT_TIME} + {"ci_url": $CI_URL} + {"build_id": $BUILD_ID}' \
      #   $TEMP_DIR/input_test_event_record.json > $TEMP_DIR/test_event_record.json

      # upload data to CI Analytics
      BQ_TABLE=$(echo "${{ inputs.big_query_table_name }}" | cut -d':' -f2)
      $BQ_COMMAND load \
        --source_format=NEWLINE_DELIMITED_JSON \
        --project_id=$GCP_PROJECT \
        $BQ_TABLE \
        $TEMP_DIR/test_event_record.json \
        $TEMP_DIR/table_schema.json
